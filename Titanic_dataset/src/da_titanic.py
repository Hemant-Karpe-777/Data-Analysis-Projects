# -*- coding: utf-8 -*-
"""DA_Titanic.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kJDRaA1AUojVuvpiWiO2sdupcu2WlmTI

#  Project Setup + Data Understanding
"""

#download data from kaggle
!pip install opendatasets

import pandas as pd
import numpy as np
import opendatasets as od
import seaborn as sns
import matplotlib.pyplot as plt
import sklearn

od.download("https://www.kaggle.com/competitions/titanic/data?select=train.csv")
#hemantk777  721b095dacb7cfa6129768282921b8fb

titanic_df=pd.read_csv("/content/titanic/train.csv")

titanic_df.head()

titanic_df.info()

titanic_df.describe()

titanic_df.isna().sum()

titanic_df['Survived'].value_counts()

# Unique values in key categorical columns
print("Sex:", titanic_df['Sex'].unique())
print("Pclass:", titanic_df['Pclass'].unique())
print("Embarked:", titanic_df['Embarked'].unique())

"""#  Data Cleaning & Formatting"""

# Drop Cabin column
titanic_df.drop('Cabin', axis=1, inplace=True)

## Fill Age with median
titanic_df['Age'].fillna(titanic_df['Age'].median(),inplace=True)

titanic_df['Embarked'].mode()[0]

# Fill Embarked with mode
titanic_df['Embarked'].fillna(titanic_df['Embarked'].mode()[0], inplace=True)

titanic_df.isna().sum()

# Convert Survived, Pclass, Sex, Embarked to category
cat_cols = ['Survived', 'Pclass', 'Sex', 'Embarked']
for col in cat_cols:
    titanic_df[col] = titanic_df[col].astype('category')

titanic_df.info()

"""#  Univariate & Bivariate Visual EDA"""

sns.countplot(x='Survived', data=titanic_df)
plt.title("Survival Count")
plt.xticks([0,1], ['Died', 'Survived'])
plt.show()

sns.countplot(x='Sex', data=titanic_df)
plt.title("Gender Count")
plt.show()

sns.countplot(x='Pclass', data=titanic_df)
plt.title("Passenger Class Count")
plt.show()

sns.histplot(titanic_df['Age'], kde=True, bins=30)
plt.title("Age Distribution")
plt.show()

sns.countplot(x='Sex', hue='Survived', data=titanic_df)
plt.title("Survival by Gender")
plt.show()

sns.countplot(x='Pclass', hue='Survived', data=titanic_df)
plt.title("Survival by Class")
plt.show()

sns.boxplot(x='Survived', y='Age', data=titanic_df)
plt.title("Age vs Survival")
plt.xticks([0,1], ['Died', 'Survived'])
plt.show()

sns.heatmap(titanic_df.select_dtypes(include='number').corr(), annot=True, cmap='coolwarm')
plt.title("Correlation Matrix")
plt.show()

"""# Feature Engineering on Titanic"""

# creat family size
titanic_df['FamilySize'] = titanic_df['SibSp'] + titanic_df['Parch'] + 1

#Binning Age into Categories , Divides a numeric column (Age) into interval bins.
titanic_df['AgeGroup'] = pd.cut(titanic_df['Age'], bins=[0, 12, 18, 35, 60, 100],
                        labels=['Child', 'Teen', 'YoungAdult', 'Adult', 'Senior'])

# Extract Title from Name
titanic_df['Title'] = titanic_df['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())
titanic_df['Title'].value_counts()

titanic_df['Title'] = titanic_df['Title'].replace(['Lady','Countess','Capt','Col','Don','Dr',
 'Major','Rev','Sir','Jonkheer','Dona'], 'Other')
titanic_df['Title'] = titanic_df['Title'].replace(['Mlle', 'Ms'], 'Miss')
titanic_df['Title'] = titanic_df['Title'].replace('Mme', 'Mrs')

#Encode Categorical Features
titanic_df = pd.get_dummies(titanic_df, columns=['Sex', 'Embarked','Title', 'AgeGroup'], drop_first=True)

#Drop Unnecessary Columns
titanic_df.drop(['Ticket', 'Name', 'PassengerId'], axis=1, inplace=True)

titanic_df.head()

titanic_df.shape

"""# Machine Learning : Logistic Regression Modeling"""

X = titanic_df.drop('Survived', axis=1)
y = titanic_df['Survived']

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42)

from sklearn.linear_model import LogisticRegression

model = LogisticRegression(max_iter=200)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

print("Accuracy:", accuracy_score(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

import joblib
joblib.dump(model, "LogisticRegression_model.pkl")

"""# Model Optimization + Final Titanic Project Polish

"""

#Use Pipeline + Scaling + CV
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score

# Create pipeline with scaling
pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('lr', LogisticRegression(max_iter=200))
])

# Cross-validation
scores = cross_val_score(pipeline, X, y, cv=5)
print("Cross-Validated Accuracy:", scores.mean())

#Fit Final Model & Evaluate
pipeline.fit(X_train, y_train)
y_pred = pipeline.predict(X_test)

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

print("Accuracy:", accuracy_score(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

# Plot Confusion Matrix
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import ConfusionMatrixDisplay

ConfusionMatrixDisplay.from_estimator(pipeline, X_test, y_test, cmap='Blues')
plt.title("Confusion Matrix")
plt.show()

"""## Author
Hemant Karpe
ðŸ“§ hemant777.karpe@gmail.com
ðŸ”— [LinkedIn](https://www.linkedin.com/in/hemant-karpe)
"""